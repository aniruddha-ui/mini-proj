{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmH3ROKjywPf"
      },
      "source": [
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import cv2\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kdg8qOPywjN"
      },
      "source": [
        "#url https://www.kaggle.com/c/cifar-10/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW-epCyKywl7"
      },
      "source": [
        "zipfile.ZipFile('CIFAR_10_train.zip').extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY6A4s2Uywn6"
      },
      "source": [
        "def plot_images(img):\n",
        "  fig, axes=plt.subplots(2,8,figsize=(13,3))\n",
        "  for i in range(8):\n",
        "    axes[0,i].imshow(img[i])\n",
        "    axes[0,i].axis('off')\n",
        "    axes[1,i].imshow(img[i+8])\n",
        "    axes[1,i].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlYYnQiMywqz"
      },
      "source": [
        "img_database=[]\n",
        "base_path= '/content/'\n",
        "cartoon = base_path +'train/'\n",
        "\n",
        "for img in os.listdir(cartoon):\n",
        "  try:\n",
        "    img_array = cv2.imread(os.path.join(cartoon,img))\n",
        "    img_database.append(img_array)\n",
        "\n",
        "  except Exception as e:\n",
        "    pass\n",
        "\n",
        "img_database = np.array(img_database)\n",
        "print(img_database.shape)\n",
        "total_num_images = 2000\n",
        "img_database = np.array(img_database[0:total_num_images])\n",
        "orig_img = img_database.astype('float32')\n",
        "orig_img = orig_img/255\n",
        "plot_images(orig_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D0xO8C7ywtx"
      },
      "source": [
        "orig_img_noisy = orig_img + 0.1 * np.random.normal(loc=0.0, scale=1.0, size=orig_img.shape)\n",
        "orig_img_noisy= np.clip(orig_img_noisy,0,1)\n",
        "plot_images(orig_img_noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP8d9MDsywva"
      },
      "source": [
        "print(orig_img.shape)\n",
        "X_T = np.transpose(orig_img,(0,3,1,2))\n",
        "print(X_T.shape)\n",
        "X_T_noise = np.transpose(orig_img_noisy,(0,3,1,2))\n",
        "\n",
        "X_flat = X_T.reshape(-1,1024)\n",
        "print(X_flat.shape)\n",
        "X_flat_noise = X_T_noise.reshape(-1,1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoriKglyywx7"
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 10000\n",
        "batch_size = 100\n",
        "display_step = 100\n",
        "examples_to_show = 8\n",
        "\n",
        "n_hidden_1 = 512\n",
        "n_hidden_2 = 256\n",
        "n_hidden_3 = 128\n",
        "n_input = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Za1zmkvyw0U"
      },
      "source": [
        "X = tf.placeholder(\"float\",[None,n_input])\n",
        "Y = tf.placeholder(\"float\",[None,n_input])\n",
        "\n",
        "weights = {\n",
        "    'encoder_h1': tf.Variable(tf.truncated_normal([n_input,n_hidden_1],stddev=0.01)),\n",
        "    'encoder_h2': tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2],stddev=0.01)),\n",
        "    'encoder_h3': tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3],stddev=0.01)),\n",
        "    'decoder_h1': tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_2],stddev=0.01)),\n",
        "    'decoder_h2': tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_1],stddev=0.01)),\n",
        "    'decoder_h3': tf.Variable(tf.truncated_normal([n_hidden_1,n_input],stddev=0.01)),\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'encoder_b1': tf.Variable(tf.truncated_normal([n_hidden_1],stddev=0.01)),\n",
        "    'encoder_b2': tf.Variable(tf.truncated_normal([n_hidden_2],stddev=0.01)),\n",
        "    'encoder_b3': tf.Variable(tf.truncated_normal([n_hidden_3],stddev=0.01)),\n",
        "    'decoder_b1': tf.Variable(tf.truncated_normal([n_hidden_2],stddev=0.01)),\n",
        "    'decoder_b2': tf.Variable(tf.truncated_normal([n_hidden_1],stddev=0.01)),\n",
        "    'decoder_b3': tf.Variable(tf.truncated_normal([n_input],stddev=0.01)),\n",
        "}\n",
        "\n",
        "def encoder(x):\n",
        "  layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x,weights['encoder_h1']),biases['encoder_b1']))\n",
        "  layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1,weights['encoder_h2']),biases['encoder_b2']))\n",
        "  layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2,weights['encoder_h3']),biases['encoder_b3']))\n",
        "  return layer_3\n",
        "\n",
        "def decoder(x):\n",
        "  layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x,weights['decoder_h1']),biases['decoder_b1']))\n",
        "  layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1,weights['decoder_h2']),biases['decoder_b2']))\n",
        "  layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2,weights['decoder_h3']),biases['decoder_b3']))\n",
        "  return layer_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrEfFaGyyw2x"
      },
      "source": [
        "encoder_op = encoder(X)\n",
        "decoder_op = decoder(encoder_op)\n",
        "y_pred = decoder_op\n",
        "cost = tf.reduce_mean(tf.pow(Y-y_pred,2))\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbld61jnyw5M"
      },
      "source": [
        "start = time.time()\n",
        "total_batch = int (X_flat.shape[0]/batch_size)\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "for epoch in range(training_epochs):\n",
        "  start = 0; end = batch_size\n",
        "  for i in range(total_batch-1):\n",
        "    index = np.arange(start,end)\n",
        "    np.random.shuffle(index)\n",
        "    batch_xs = X_flat[index]\n",
        "    batch_xsn = X_flat_noise[index]\n",
        "    start = end; end = start + batch_size\n",
        "    _, c = sess.run([optimizer,cost],feed_dict={X:batch_xsn,Y:batch_xs})\n",
        "\n",
        "  if (epoch%1000==0):\n",
        "    print ('Epoch: {0:05d}    loss: {1:f}').format(epoch, c)\n",
        "print(\"Optimization Finished:\")\n",
        "end = time.time()\n",
        "print(\"Time taken: {0}\".format(end-start))\n",
        "\n",
        "index = np.random.randint(orig_img.shape[0],size=examples_to_show)\n",
        "print(index)\n",
        "index = np.sort(index)\n",
        "print(index)\n",
        "RGB_index = np.concatenate((index*3,index*3 +1, index*3 +2))\n",
        "print(RGB_index)\n",
        "RGB_index = np.sort(RGB_index)\n",
        "print(RGB_index)\n",
        "denoised_image = sess.run(y_pred,feed_dict={X:X_flat_noise[RGB_index]})\n",
        "print(denoised_image.shape)\n",
        "denoised_image = np.reshape(denoised_image, (examples_to_show,3,32,32))\n",
        "print(denoised_image.shape)\n",
        "denoised_image = np.transpose(denoised_image, (0,2,3,1))\n",
        "print(denoised_image.shape)\n",
        "\n",
        "f,a = plt.subplots(3,examples_to_show,figsize=(13,5))\n",
        "for i in range(examples_to_show):\n",
        "  a[0][i].imshow(orig_img[index[i]])\n",
        "  a[0,i].axis('off')\n",
        "  a[1][i].imshow(orig_img_noisy[index[i]])\n",
        "  a[1,i].axis('off')\n",
        "  a[2][i].imshow(denoised_image[i])\n",
        "  a[2,i].axis('off')\n",
        "\n",
        "f.show()\n",
        "plt.draw()\n",
        "\n",
        "def plot_max_active(x):\n",
        "  fig,axes = plt.subplots(nrows=10,ncols=10,figsize=(13,10))\n",
        "  fig.subplots_adjust(hspace=.1,wspace=0)\n",
        "  img_h = img_w = np.sqrt(x.shape[0]).astype(int)\n",
        "  for i,ax in enumerate(axes.flat):\n",
        "    ax.imshow(x[:,i].reshape((img_h,img_w)))\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticklabels([])\n",
        "  plt.show()\n",
        "\n",
        "plot_max_active(sess.run(weights['encoder_h1']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}